# Lab8 文件系统实验报告

- 学号：2310675
- 实验：Lab 8 文件系统（VFS + SFS + 基于文件系统的 exec）
- 代码目录：`lab8/`

## 一、实验目标与完成情况

本实验在 ucore 内核中引入文件系统支持，并在此基础上实现：

- VFS 抽象层的文件访问路径（open/read/write/close/seek 等）
- SFS（Simple FS）基于 inode 的文件组织与数据块读写
- “一切皆文件”的设备文件（如 `stdin:`/`stdout:`）
- 基于文件系统的程序加载与执行（`exec` 从磁盘文件加载 ELF）

本次完成内容：

- 练习1：实现 `sfs_io_nolock()` 的文件读写逻辑
- 练习2：实现基于文件系统的 `load_icode()`，并补全 `proc_run/do_fork/alloc_proc` 相关改动
- Challenge1/Challenge2：给出 PIPE / 软硬链接机制设计方案（语义 + 数据结构 + 接口 + 同步互斥）

### 代码修改摘要（对应 LAB8 标注处）

- `lab8/kern/fs/sfs/sfs_inode.c`：补全 `sfs_io_nolock()`（LAB8:EXERCISE1）
- `lab8/kern/process/proc.c`：
  - `alloc_proc()` 初始化 `proc->filesp`
  - `proc_run()` 切换页表并 `flush_tlb()`
  - `do_fork()` 增加 `copy_files()` 及错误清理（LAB8:EXERCISE2）
  - `load_icode()`：从 fd 读取 ELF 并加载到新 mm（LAB8:EXERCISE2）
- `lab8/kern/schedule/default_sched_stride.c`：将 LAB6 “YOUR CODE”标注替换为学号（保持原有实现）
- `lab8/kern/mm/pmm.c`：补全 `copy_range()`（来自 LAB5 的页复制 + 映射），保证 `fork()` 后子进程能正常执行（否则会出现 Instruction page fault）
- `lab8/kern/trap/trap.c`：完善页故障输出与处理：打印 `epc/tval` 并在用户态故障时退出进程，避免无限刷屏
- `lab8/user/badsegment.c` / `lab8/user/faultread.c` / `lab8/user/faultreadkernel.c` / `lab8/user/testbss.c`：改为“fork + wait 自检”形式：子进程触发异常应被内核杀死，父进程验证退出码并打印 `pass`，避免在 `sh` 中显示 `error: -9 - process is killed`

## 二、实验环境与运行验证

- 在 `lab8/` 下编译：`make -j4`
- 运行：`make qemu`
- 进入用户态 `sh` 后，可执行（示例）：`hello`、`exit` 等 SFS 中的用户程序
- `fork()`/`exec()` 验证：在 `sh` 内运行任意外部命令会触发 `fork()`（如 `hello`/`sleep`/`forktest`），应能正常运行并回到 shell
- 异常验证：`faultread`/`badsegment` 等程序触发页故障时，应打印一次故障信息并退出回到 shell（不应无限刷屏）

### 评分脚本（make grade）

在 `lab8/` 下执行：`make grade`

评分结果（本地运行）：

```text
.img gmake[1]: Leaving directory '/home/wsy/lab8'
  -sh execve:                                OK
  -user sh :                                 OK
Total Score: 100/100
```

## 三、练习0：填写已有实验

实验指导书要求将 LAB2~LAB7 已完成内容合入 LAB8。为保证 LAB8 能独立编译与运行，需要满足以下“最低可用”条件：

- 进程管理、虚拟内存管理等（LAB2~LAB5）可用，能创建进程并切换上下文
- `fork()` 依赖 LAB5 的 `copy_range()`：需要能把父进程的用户态页内容复制到子进程并建立映射，否则子进程返回用户态会立刻触发 Instruction page fault
- 文件系统相关新增字段（`proc_struct::filesp`）在进程创建/复制时正确初始化与复制
- 调度、同步相关（LAB6/LAB7）即使未深度扩展，也应保证不影响 LAB8 的文件系统与 `exec` 主流程

本次 LAB8 代码中涉及 LAB6/LAB7 的部分以“可编译可运行”为目标，LAB8 的关键功能不依赖 Challenge 的扩展实现。

## 四、练习1：完成读文件操作 `sfs_io_nolock()`（需要编码）

### 1. 目标与位置

**目标**：实现 SFS 文件（非目录）在指定 `offset` 上的读/写，将磁盘数据块与内存缓冲区互相搬运，并返回真实读写长度。

**位置**：`lab8/kern/fs/sfs/sfs_inode.c` 中 `sfs_io_nolock()` 函数（第 617-751 行）

### 2. 核心思路（三段式 I/O）

`sfs_io_nolock()` 的关键是把"任意偏移 + 任意长度"的读写拆成三段，这是因为：

- **磁盘块大小固定**：SFS_BLKSIZE = 4096 字节
- **读写可能跨多个块**：用户可能从中间偏移开始，读取跨越多个块的数据
- **首尾可能非对齐**：起始和结束位置可能不在块边界上

**三段式划分**：

1. **首块非对齐部分**（First Partial Block）
   - 条件：`offset % SFS_BLKSIZE != 0`（起始位置不在块边界）
   - 方法：使用 `sfs_rbuf/sfs_wbuf` 对单块做"部分读写"
   - 处理：只读/写块内从 `offset` 到块末尾的部分

2. **中间整块部分**（Middle Aligned Blocks）
   - 条件：起始和结束位置都块对齐
   - 方法：使用 `sfs_rblock/sfs_wblock` 批量读写整块
   - 优化：可以合并连续磁盘块，减少 I/O 次数（代码中实现了连续块合并优化）

3. **尾块非对齐部分**（Last Partial Block）
   - 条件：`endpos % SFS_BLKSIZE != 0`（结束位置不在块边界）
   - 方法：再次使用 `sfs_rbuf/sfs_wbuf` 处理最后剩余字节
   - 处理：只读/写块内从块开始到 `endpos` 的部分

### 3. 实现细节与代码解析

#### 3.1 准备工作：计算关键参数

```c
// lab8:2310675 保存原始 offset，便于在写入后更新文件大小
off_t startpos = offset;
// lab8:2310675 计算首个读写块内的偏移量
blkoff = offset % SFS_BLKSIZE;  // 块内偏移

uint32_t blkno = offset / SFS_BLKSIZE;          // 起始逻辑块号
uint32_t nblks = endpos / SFS_BLKSIZE - blkno;  // 需要处理的块数
```

**关键变量说明**：
- `blkno`：文件的逻辑块号（从 0 开始）
- `blkoff`：块内偏移（0 到 SFS_BLKSIZE-1）
- `nblks`：需要处理的完整块数量
- `startpos`：用于写入后更新文件大小

#### 3.2 第一阶段：处理首块非对齐部分

```c
// (1) handle the first unaligned block (use sfs_buf_op for partial block io)
if (blkoff != 0) {
    // 计算本次读写大小：
    // - 如果只跨一个块：size = endpos - offset
    // - 如果跨多个块：size = 从 offset 到块末尾的部分 = SFS_BLKSIZE - blkoff
    size = (nblks != 0) ? (SFS_BLKSIZE - blkoff) : (size_t)(endpos - offset);

    // 将文件逻辑块号映射为磁盘物理块号
    if ((ret = sfs_bmap_load_nolock(sfs, sin, blkno, &ino)) != 0) {
        goto out;
    }

    // 执行块内部分读写（从 blkoff 开始，读/写 size 字节）
    if ((ret = sfs_buf_op(sfs, buf, size, ino, blkoff)) != 0) {
        goto out;
    }

    // 更新已处理字节数和缓冲区指针
    alen += size;     // 累计已处理字节数
    buf += size;      // 缓冲区指针后移
    offset += size;   // 文件偏移后移

    // 如果整个读写操作只跨一个块，直接结束
    if (nblks == 0) {
        goto out;
    }

    // 移动到下一个块
    blkno++;
    nblks--;
    blkoff = 0;  // 后续都从块开始位置处理
}
```

**关键函数说明**：
- `sfs_bmap_load_nolock(sfs, sin, blkno, &ino)`：
  - 功能：将文件的逻辑块号 `blkno` 映射为磁盘物理块号 `ino`
  - 自动分配：如果是写操作且块不存在，会自动分配新块
  - 索引结构：支持直接索引（前12块）和间接索引（后续块）

- `sfs_buf_op(sfs, buf, size, ino, blkoff)`：
  - 功能：读/写磁盘块 `ino` 的部分内容（从 `blkoff` 开始的 `size` 字节）
  - 读操作：`sfs_rbuf` - 读取磁盘块到内存
  - 写操作：`sfs_wbuf` - 将内存数据写入磁盘块

#### 3.3 第二阶段：处理中间整块部分（含连续块优化）

```c
// (2) handle aligned blocks (use sfs_block_op for block io)
while (nblks > 0) {
    uint32_t run_ino, run_nblks = 1;

    // 映射当前块的物理块号
    if ((ret = sfs_bmap_load_nolock(sfs, sin, blkno, &run_ino)) != 0) {
        goto out;
    }

    // lab8:2310675 优化：合并连续磁盘块，减少 I/O 次数
    // 检查后续块是否在磁盘上连续排列
    while (run_nblks < nblks) {
        uint32_t next_ino;
        if ((ret = sfs_bmap_load_nolock(sfs, sin, blkno + run_nblks, &next_ino)) != 0) {
            goto out;
        }
        // 如果不连续，停止合并
        if (next_ino != run_ino + run_nblks) {
            break;
        }
        run_nblks++;  // 连续，继续合并
    }

    // 批量读写 run_nblks 个连续块
    if ((ret = sfs_block_op(sfs, buf, run_ino, run_nblks)) != 0) {
        goto out;
    }

    // 更新进度
    size = (size_t)run_nblks * SFS_BLKSIZE;
    alen += size;
    buf += size;
    offset += size;
    blkno += run_nblks;
    nblks -= run_nblks;
}
```

**优化说明**：
- **连续块合并**：如果文件的多个逻辑块在磁盘上物理连续（`ino+1, ino+2, ...`），可以一次性读写多个块，显著减少 I/O 次数
- **判断条件**：`next_ino == run_ino + run_nblks` 表示磁盘块连续
- **性能提升**：对于大文件顺序读写，可以大幅减少系统调用和磁盘访问次数

#### 3.4 第三阶段：处理尾块非对齐部分

```c
// (3) handle the last partial block (use sfs_buf_op for partial block io)
if (offset < endpos) {
    size = (size_t)(endpos - offset);  // 剩余字节数

    // 映射最后一个块的物理块号
    if ((ret = sfs_bmap_load_nolock(sfs, sin, blkno, &ino)) != 0) {
        goto out;
    }

    // 从块开始位置读/写 size 字节
    if ((ret = sfs_buf_op(sfs, buf, size, ino, 0)) != 0) {
        goto out;
    }

    alen += size;
}
```

#### 3.5 收尾工作：更新文件大小（写操作）

```c
out:
    *alenp = alen;  // 返回实际读写的字节数

    // 如果是写操作且写入位置超过了原文件大小，更新文件大小
    if (startpos + alen > sin->din->size) {
        sin->din->size = startpos + alen;
        sin->dirty = 1;  // 标记 inode 已修改，需要写回磁盘
    }
    return ret;
```

### 4. 关键边界处理

#### 4.1 越界检查（函数开头）

```c
// 检查偏移是否合法
if (offset < 0 || offset >= SFS_MAX_FILE_SIZE || offset > endpos) {
    return -E_INVAL;
}

// 如果偏移等于结束位置，没有字节需要读写
if (offset == endpos) {
    return 0;
}

// 截断超出最大文件大小的部分
if (endpos > SFS_MAX_FILE_SIZE) {
    endpos = SFS_MAX_FILE_SIZE;
}
```

#### 4.2 读操作特殊处理

```c
if (!write) {
    // 读取位置超过文件大小，直接返回 0（EOF）
    if (offset >= din->size) {
        return 0;
    }
    // 截断读取范围到文件实际大小
    if (endpos > din->size) {
        endpos = din->size;
    }
}
```

**说明**：读操作不能读取文件大小之外的内容（会读到未分配的块），而写操作可以扩展文件大小。

### 5. 与上层调用链的对应关系

以用户态 `read()` 系统调用为例，完整调用链为：

```
用户程序调用 read(fd, buf, len)
  ↓
sys_read (syscall.c)                      系统调用入口
  ↓
sysfile_read (sysfile.c)                  文件系统系统调用层
  ↓ (使用 4KB 内核缓冲区分段传输)
file_read (file.c)                        文件描述符层
  ↓ (fd → file → inode)
vop_read (vfs.h)                          VFS 抽象层（inode_ops 函数指针）
  ↓
sfs_read (sfs_inode.c)                    SFS 具体实现（调用 sfs_io）
  ↓
sfs_io (sfs_inode.c)                      加锁包装
  ↓
sfs_io_nolock (sfs_inode.c)               **本练习实现的核心函数**
  ↓
sfs_rbuf / sfs_rblock (sfs_io.c)          块级 I/O 操作
  ↓
sfs_rwblock_nolock (sfs_io.c)             磁盘块读写
  ↓
dop_io (dev.c)                            设备抽象层
  ↓
disk0_io (ide.c)                          IDE 磁盘驱动
```

这体现了操作系统课程中强调的**分层抽象思想**：
- **用户接口层**：系统调用接口
- **VFS 层**：统一文件系统接口（inode/file 抽象）
- **具体文件系统层**：SFS 实现
- **块设备层**：磁盘驱动

### 6. 实现要点总结

1. **三段式 I/O**：处理非对齐读写的标准方法，避免了复杂的边界计算
2. **块映射**：每次 I/O 前必须通过 `sfs_bmap_load_nolock` 将逻辑块号转换为物理块号
3. **连续块优化**：合并连续磁盘块可以显著提升性能
4. **文件大小更新**：写操作可能扩展文件，需要更新 `din->size` 并标记 `dirty`
5. **读写分离**：读操作需要截断到文件大小，写操作可以自动分配新块

## 五、练习2：完成基于文件系统的执行程序机制（需要编码）

### 1. 目标与背景

**目标**：将 LAB5 中"从内存镜像加载 ELF"的 `load_icode()` 改为"从文件系统读取 ELF 文件并加载"，使 `exec` 可以执行 SFS 中的用户程序（如 `sh/hello/exit` 等）。

**关键区别**：
- **Lab5**：`load_icode(binary, size)` - binary 是内存指针，直接读取内存中的 ELF 数据
- **Lab8**：`load_icode(fd, argc, kargv)` - fd 是文件描述符，需要通过文件系统接口读取磁盘上的 ELF 文件

**核心文件位置**：`lab8/kern/process/proc.c` 中 `load_icode()` 函数（第 726-1059 行）

### 2. 相关改动点概述

练习2涉及多个函数的修改，形成完整的文件系统支持：

#### 2.1 `alloc_proc()` - 初始化进程文件上下文（第 155 行）

```c
proc->filesp = NULL; // lab8:2310675 初始化进程的文件上下文指针
```

**作用**：每个进程需要维护自己的文件描述符表（`files_struct`），`alloc_proc()` 中必须将其初始化为 NULL。

#### 2.2 `proc_run()` - 切换地址空间后刷新 TLB（第 275-287 行）

```c
if (proc != current) {
    bool intr_flag;
    struct proc_struct *prev = current;
    local_intr_save(intr_flag);
    {
        // lab8:2310675 切换地址空间后刷新 TLB，避免使用旧的 TLB 项
        current = proc;
        lsatp(proc->pgdir);  // 切换页表
        flush_tlb();         // 刷新 TLB（Lab8 新增）
        switch_to(&(prev->context), &(proc->context));
    }
    local_intr_restore(intr_flag);
}
```

**作用**：进程切换时需要切换页表（`lsatp`），但 TLB（Translation Lookaside Buffer）中仍缓存着旧进程的虚拟地址映射。如果不刷新 TLB，新进程可能访问到错误的物理地址，导致严重错误。

#### 2.3 `do_fork()` - 复制文件上下文（第 554-606 行）

```c
// lab8:2310675（LAB8 更新）复制（或共享）文件系统上下文
if ((ret = copy_files(clone_flags, proc)) != 0) {
    goto bad_fork_cleanup_fs;
}

// ... 其他步骤 ...

fork_out:
    return ret;

bad_fork_cleanup_fs: // for LAB8
    put_files(proc);
bad_fork_cleanup_kstack:
    put_kstack(proc);
bad_fork_cleanup_proc:
    kfree(proc);
    goto fork_out;
```

**作用**：
- `copy_files()`：根据 `clone_flags` 决定是共享父进程的文件描述符表（`CLONE_FS`）还是复制一份新的
- 失败清理路径：如果后续步骤失败，需要释放已分配的文件上下文（`put_files`）

#### 2.4 `load_icode()` - 核心实现（下面详细展开）

### 3. `load_icode()` 核心流程详解

`load_icode()` 是本练习的核心函数，需要完成以下步骤：

#### 步骤1：创建新的地址空间 mm_struct（第 749-760 行）

```c
/*
 * ========== 步骤1：创建新的地址空间 mm_struct ==========
 * mm_struct 管理进程的虚拟地址空间（VMA链表、页目录表等）
 */
if ((mm = mm_create()) == NULL) {
    goto bad_mm;
}

/*
 * ========== 步骤2：建立新的页目录表 ==========
 * setup_pgdir 分配新页目录表并拷贝内核映射（内核空间部分需要共享）
 * 用户空间部分目前为空，后续通过 mm_map + pgdir_alloc_page 建立映射
 */
if (setup_pgdir(mm) != 0) {
    goto bad_pgdir_cleanup_mm;
}
```

**关键数据结构**：
- `mm_struct`：进程的内存管理结构，包含：
  - `vma_list`：虚拟内存区域（VMA）链表
  - `pgdir`：页目录表指针
  - `mm_count`：引用计数

#### 步骤2：读取并验证 ELF Header（第 770-777 行）

```c
/*
 * ========== 步骤3.1：读取并验证 ELF Header ==========
 * ELF Header 位于文件开头（offset=0），包含：
 * - e_magic: 魔数（0x464C457F）用于识别 ELF 文件
 * - e_entry: 程序入口地址（后续设置 trapframe->epc）
 * - e_phoff: Program Header Table 在文件中的偏移
 * - e_phnum: Program Header 数量
 */
struct elfhdr elf;
if ((ret = load_icode_read(fd, &elf, sizeof(elf), 0)) != 0) {
    goto bad_elf_cleanup_pgdir;
}
if (elf.e_magic != ELF_MAGIC) {
    ret = -E_INVAL_ELF;
    goto bad_elf_cleanup_pgdir;
}
```

**ELF Header 关键字段**：
```c
struct elfhdr {
    uint32_t e_magic;   // ELF 魔数：0x464C457F
    uint32_t e_entry;   // 程序入口地址（main 函数地址）
    uint32_t e_phoff;   // Program Header Table 偏移
    uint16_t e_phnum;   // Program Header 数量
    // ... 其他字段
};
```

#### 步骤3：遍历 Program Header 加载段（第 789-900 行）

```c
struct proghdr ph;
for (int i = 0; i < elf.e_phnum; i++) {
    // 读取第 i 个 Program Header
    if ((ret = load_icode_read(fd, &ph, sizeof(ph), elf.e_phoff + i * sizeof(ph))) != 0) {
        goto bad_cleanup_mmap;
    }

    // 只处理 PT_LOAD 类型的段（代码段、数据段等）
    if (ph.p_type != ELF_PT_LOAD) {
        continue;
    }

    // 合法性检查：文件大小不能超过内存大小
    if (ph.p_filesz > ph.p_memsz) {
        ret = -E_INVAL_ELF;
        goto bad_cleanup_mmap;
    }
```

**Program Header 关键字段**：
```c
struct proghdr {
    uint32_t p_type;    // 段类型（PT_LOAD=可加载段）
    uint32_t p_offset;  // 段在文件中的偏移
    uint32_t p_va;      // 段的虚拟地址
    uint32_t p_filesz;  // 段在文件中的大小（TEXT+DATA）
    uint32_t p_memsz;   // 段在内存中的大小（TEXT+DATA+BSS）
    uint32_t p_flags;   // 段权限（R/W/X）
};
```

##### 3.1 设置段权限（第 810-822 行）

```c
/*
 * 根据 ELF 段权限标志设置 VMA 和 PTE 权限
 * - vm_flags: VMA 权限（VM_READ/VM_WRITE/VM_EXEC）
 * - perm:     页表项权限（PTE_R/PTE_W/PTE_X + PTE_U + PTE_V）
 */
uint32_t vm_flags = 0, perm = PTE_U | PTE_V;
if (ph.p_flags & ELF_PF_R) {
    vm_flags |= VM_READ;
    perm |= PTE_R;
}
if (ph.p_flags & ELF_PF_W) {
    vm_flags |= VM_WRITE;
    perm |= PTE_W | PTE_R; // RISC-V 要求可写页必须同时可读
}
if (ph.p_flags & ELF_PF_X) {
    vm_flags |= VM_EXEC;
    perm |= PTE_X | PTE_R; // RISC-V 要求可执行页必须同时可读
}
```

**RISC-V 特殊要求**：
- 可写页必须同时可读（`PTE_W` 必须配合 `PTE_R`）
- 可执行页必须同时可读（`PTE_X` 必须配合 `PTE_R`）

##### 3.2 创建 VMA（第 831-833 行）

```c
/*
 * ========== 步骤3.3：为段创建 VMA ==========
 * mm_map 在地址空间中插入一个新的虚拟内存区域
 * - 起始地址：ph.p_va
 * - 大小：ph.p_memsz（包含 BSS，BSS 部分在后续 memset 为 0）
 * - 权限：vm_flags
 */
if ((ret = mm_map(mm, (uintptr_t)ph.p_va, (size_t)ph.p_memsz, vm_flags, NULL)) != 0) {
    goto bad_cleanup_mmap;
}
```

**VMA 的作用**：标记虚拟地址区域合法，缺页异常处理时会检查地址是否在 VMA 范围内。

##### 3.3 拷贝 TEXT/DATA 段内容（第 845-869 行）

```c
/*
 * ========== 步骤3.4：拷贝 TEXT/DATA 段内容（文件中的数据部分） ==========
 * p_filesz 表示文件中实际存储的数据大小（不包括 BSS）
 * 需要逐页分配物理页，并从文件中读取内容拷贝到页中
 *
 * 难点：段的起始地址 p_va 可能不是页对齐的，需要处理：
 * - la: 页对齐的虚拟地址（向下取整到 PGSIZE）
 * - off: 段在页内的偏移（start - la）
 * - size: 本次拷贝的字节数（不超过页边界，不超过段末尾）
 */
uintptr_t start = (uintptr_t)ph.p_va;
uintptr_t end = start + (size_t)ph.p_filesz;
uintptr_t la = ROUNDDOWN(start, PGSIZE);  // 页对齐地址
off_t foff = (off_t)ph.p_offset;          // 文件偏移
struct Page *page;

ret = -E_NO_MEM;
while (start < end) {
    // 为虚拟地址 la 分配物理页并建立映射（PTE 设置为 perm）
    if ((page = pgdir_alloc_page(mm->pgdir, la, perm)) == NULL) {
        goto bad_cleanup_mmap;
    }

    size_t off = start - la; // 段在页内的起始偏移
    size_t size = PGSIZE - off; // 本页剩余空间
    if (end < la + PGSIZE) {
        size = end - start; // 段末尾在本页内，缩小拷贝大小
    }

    // 从文件偏移 foff 读取 size 字节到页的虚拟地址 page2kva(page) + off
    if ((ret = load_icode_read(fd, page2kva(page) + off, size, foff)) != 0) {
        goto bad_cleanup_mmap;
    }

    start += size;
    foff += size;
    la += PGSIZE;
}
```

**处理非页对齐的关键**：
- `la = ROUNDDOWN(start, PGSIZE)`：向下取整到页边界
- `off = start - la`：段在页内的起始偏移
- `size = min(PGSIZE - off, end - start)`：本次拷贝大小

**示例**：假设段从地址 0x1234 开始，PGSIZE=4096
- `la = 0x1000`（页对齐地址）
- `off = 0x234`（段在页内的偏移）
- 第一页只拷贝 `4096 - 0x234 = 3548` 字节

##### 3.4 处理 BSS 段（第 880-899 行）

```c
/*
 * ========== 步骤3.5：处理 BSS 段（memset 为 0） ==========
 * BSS 段是未初始化的全局变量/静态变量，ELF 文件中不存储内容
 * 区间：[p_filesz, p_memsz) 需要分配页并清零
 *
 * 注意：前面已经为 [0, p_filesz) 分配并拷贝了页，BSS 可能：
 * 1. 与 DATA 段共享最后一页（start 不是页对齐）
 * 2. 需要额外分配新页（start 已页对齐）
 */
end = (uintptr_t)ph.p_va + (size_t)ph.p_memsz;
la = ROUNDDOWN(start, PGSIZE);

while (start < end) {
    page = get_page(mm->pgdir, la, NULL); // 尝试获取已分配的页
    if (page == NULL) {
        // BSS 的起始部分可能在新页，需要分配新页
        if ((page = pgdir_alloc_page(mm->pgdir, la, perm)) == NULL) {
            goto bad_cleanup_mmap;
        }
    }

    size_t off = start - la;
    size_t size = PGSIZE - off;
    if (end < la + PGSIZE) {
        size = end - start;
    }

    // BSS 段清零（未初始化的全局变量/静态变量在程序启动时必须为 0）
    memset(page2kva(page) + off, 0, size);

    start += size;
    la += PGSIZE;
}
```

**BSS 段的特殊性**：
- C 标准规定：未初始化的全局变量和静态变量初始值为 0
- ELF 文件不存储全 0 数据（节省空间），只记录大小
- 加载时需要分配内存并 `memset(0)`

#### 步骤4：建立用户栈（第 909-974 行）

```c
/*
 * ========== 步骤4：建立用户栈 VMA ==========
 * 用户栈位于高地址：[USTACKTOP - USTACKSIZE, USTACKTOP)
 * - USTACKTOP: 用户栈顶（虚拟地址最高处）
 * - USTACKSIZE: 栈大小（默认 256 页 = 1MB）
 * - 权限：可读可写，标记为栈区域（VM_STACK）
 */
if ((ret = mm_map(mm, USTACKTOP - USTACKSIZE, USTACKSIZE, VM_READ | VM_WRITE | VM_STACK, NULL)) != 0) {
    goto bad_cleanup_mmap;
}

/*
 * 预分配用户栈页（ucore Lab8 没有缺页异常处理，必须提前分配）
 * 至少分配 4 页（16KB），确保栈有足够空间用于函数调用
 */
size_t stack_pages = ROUNDUP(USTACKTOP - sp, PGSIZE) / PGSIZE;
if (stack_pages < 4) {
    stack_pages = 4;
}
for (size_t i = 0; i < stack_pages; i++) {
    if (pgdir_alloc_page(mm->pgdir, USTACKTOP - (i + 1) * PGSIZE, PTE_USER) == NULL) {
        ret = -E_NO_MEM;
        goto bad_cleanup_mmap;
    }
}
```

**为什么要预分配栈页？**
- ucore Lab8 未实现完整的缺页异常处理
- 如果不预分配，用户程序第一次访问栈就会触发 Page Fault，导致崩溃

#### 步骤5：构造 argc/argv（第 938-1003 行）

```c
/*
 * ========== 步骤5-6：在用户栈中构造 argc/argv（RISC-V 调用约定） ==========
 *
 * 目标栈布局（从高地址到低地址）：
 * USTACKTOP
 *   |
 *   |  [高地址]
 *   |  argv[argc-1] 的字符串内容（如 "test\0"）
 *   |  argv[argc-2] 的字符串内容
 *   |  ...
 *   |  argv[0] 的字符串内容（如 "sh\0"）
 *   |  [字符串与指针数组之间可能有对齐填充]
 *   |  NULL (0x0)                            ← uargv[argc]
 *   |  argv[argc-1] 的地址（指向上面的字符串）
 *   |  argv[argc-2] 的地址
 *   |  ...
 *   |  argv[0] 的地址                         ← uargv_ptr（传给 a1）
 *   |  [可能有对齐到 16 字节的填充]
 *   v  sp（最终栈指针，传给用户态）
 *
 * RISC-V 调用约定要求：
 * - a0 = argc（参数个数）
 * - a1 = argv（指针数组的起始地址）
 * - sp 必须 16 字节对齐
 */
uintptr_t uargv[EXEC_MAX_ARG_NUM + 1]; // 临时数组，记录每个 argv 字符串的用户空间地址
uintptr_t sp = USTACKTOP;

// 第一步：从栈顶向下依次放置 argv 字符串（逆序，从 argc-1 到 0）
for (int i = argc - 1; i >= 0; i--) {
    size_t len = strlen(kargv[i]) + 1; // 包含 '\0'
    sp -= len; // 栈向下增长
    sp = ROUNDDOWN(sp, sizeof(uintptr_t)); // 对齐到指针大小
    uargv[i] = sp; // 记录该字符串的用户空间地址
}
uargv[argc] = 0; // argv 数组末尾必须是 NULL

// 第二步：放置 argv 指针数组（argc+1 个指针）
sp -= (argc + 1) * sizeof(uintptr_t);
sp = ROUNDDOWN(sp, 16); // RISC-V ABI 要求栈指针 16 字节对齐
uintptr_t uargv_ptr = sp; // argv 数组的起始地址（传给 a1）

// 检查栈空间是否足够
if (sp < USTACKTOP - USTACKSIZE) {
    ret = -E_TOO_BIG; // 参数过多，超出栈空间
    goto bad_cleanup_mmap;
}
```

**栈布局示例**（假设 argc=2, argv=["sh", "hello"]）：
```
USTACKTOP (0x40000000)
    |
    | "hello\0"         ← uargv[1] = 0x3FFFFFF9
    | "sh\0"            ← uargv[0] = 0x3FFFFFF6
    | NULL (0x0)        ← uargv[2]
    | 0x3FFFFFF9        ← argv[1]
    | 0x3FFFFFF6        ← argv[0]
    v sp = 0x3FFFFFF0   ← 16 字节对齐
```

#### 步骤6：切换地址空间并拷贝参数（第 980-1002 行）

```c
/*
 * ========== 步骤5：切换到新的地址空间 ==========
 * 在这之后，cr3 指向新页表，可以安全地使用用户空间地址
 */
mm_count_inc(mm); // mm 引用计数 +1
current->mm = mm;
current->pgdir = PADDR(mm->pgdir); // 设置 satp（页表基址寄存器）
lsatp(current->pgdir); // 加载新页表到 CR3
flush_tlb(); // 刷新 TLB

/*
 * ========== 步骤6：将 argv 字符串和指针数组拷贝到用户栈 ==========
 * 使用 copy_to_user 安全地将内核缓冲区内容拷贝到用户空间
 */
// 拷贝各个 argv 字符串
for (int i = 0; i < argc; i++) {
    size_t len = strlen(kargv[i]) + 1;
    if (!copy_to_user(mm, (void *)uargv[i], kargv[i], len)) {
        ret = -E_INVAL;
        goto bad_after_switch;
    }
}
// 拷贝 argv 指针数组
if (!copy_to_user(mm, (void *)uargv_ptr, uargv, (argc + 1) * sizeof(uintptr_t))) {
    ret = -E_INVAL;
    goto bad_after_switch;
}
```

**为什么要用 `copy_to_user`？**
- 直接访问用户空间地址可能越界或访问非法地址
- `copy_to_user` 会检查地址合法性（是否在 VMA 范围内）

#### 步骤7：设置 trapframe（第 1015-1027 行）

```c
/*
 * ========== 步骤7：设置 trapframe 以进入用户态 ==========
 * trapframe 在 sret 返回时恢复寄存器，实现"跳转到用户态"
 *
 * 关键设置：
 * - epc = elf.e_entry：程序入口地址（sret 返回后从这里开始执行）
 * - sp = 用户栈顶（argc/argv 已准备好）
 * - a0 = argc, a1 = argv：传递命令行参数（RISC-V 调用约定）
 * - status 清除 SPP 位：sret 返回到 U-mode（用户态）
 * - 其他寄存器清零（新程序的初始状态）
 */
struct trapframe *tf = current->tf;
uintptr_t sstatus = tf->status;
memset(tf, 0, sizeof(struct trapframe));
tf->gpr.sp = sp; // 用户栈指针
tf->gpr.a0 = argc; // 第一个参数：argc
tf->gpr.a1 = uargv_ptr; // 第二个参数：argv
tf->epc = elf.e_entry; // 程序入口地址

/*
 * 设置 sstatus 寄存器：
 * - 清除 SPP 位（Supervisor Previous Privilege）：sret 返回到用户态（U-mode）
 * - 设置 SPIE 位（Supervisor Previous Interrupt Enable）：返回用户态后开启中断
 */
tf->status = (sstatus & ~SSTATUS_SPP) | SSTATUS_SPIE;
```

**trapframe 的作用**：
- 保存/恢复进程上下文（寄存器状态）
- `sret` 指令会从 trapframe 恢复寄存器，并根据 `sstatus` 的 SPP 位决定返回到用户态还是内核态

### 4. 错误恢复与资源释放要点

#### 4.1 清理路径（第 1036-1058 行）

```c
bad_after_switch:
    // lab8:2310675 销毁 mm->pgdir 前先切回内核页表，避免继续使用已释放的页表
    lsatp(boot_pgdir_pa);
    flush_tlb();
    current->pgdir = boot_pgdir_pa;
    current->mm = NULL;
    if (mm_count_dec(mm) == 0) {
        exit_mmap(mm);   // 释放所有 VMA 和物理页
        put_pgdir(mm);   // 释放页目录表
        mm_destroy(mm);  // 释放 mm_struct
    }
    sysfile_close(fd);
    return ret;

bad_cleanup_mmap:
    exit_mmap(mm);
bad_elf_cleanup_pgdir:
    put_pgdir(mm);
bad_pgdir_cleanup_mm:
    mm_destroy(mm);
bad_mm:
    sysfile_close(fd);
    return ret;
```

**关键点**：
- **切回内核页表**：如果已经切换到新页表（`lsatp`），在释放页表前必须先切回 `boot_pgdir_pa`，否则 CPU 会在释放过程中访问已释放的页表，导致崩溃
- **逆序释放**：先释放 VMA/物理页，再释放页表，最后释放 mm_struct

### 5. 完整调用链

```
用户程序调用 execve("/bin/sh", argv, envp)
  ↓
sys_exec (syscall.c)
  ↓
do_execve (proc.c)
  ↓ 释放旧地址空间（exit_mmap + put_pgdir + mm_destroy）
  ↓ 打开可执行文件（sysfile_open）
  ↓
load_icode (proc.c)                      **本练习实现的核心函数**
  ↓ mm_create + setup_pgdir
  ↓ load_icode_read (ELF header)
  ↓ 循环处理每个 Program Header：
  │   ↓ mm_map (创建 VMA)
  │   ↓ pgdir_alloc_page + load_icode_read (拷贝 TEXT/DATA)
  │   ↓ memset(0) (清零 BSS)
  ↓ mm_map (用户栈 VMA)
  ↓ pgdir_alloc_page (预分配栈页)
  ↓ 构造 argc/argv（栈布局）
  ↓ lsatp + flush_tlb (切换地址空间)
  ↓ copy_to_user (拷贝参数到用户栈)
  ↓ 设置 trapframe (epc/sp/a0/a1/status)
  ↓ sysfile_close (关闭 ELF 文件)
  ↓
__trapret (trap.S)
  ↓ sret 指令（返回用户态）
  ↓
用户程序的 main(argc, argv) 开始执行
```

### 6. 实现要点总结

1. **文件读取**：使用 `load_icode_read(fd, buf, len, offset)` 替代直接内存访问
2. **段加载**：处理非页对齐的段起始地址，逐页分配并拷贝数据
3. **BSS 处理**：检查页是否已分配（与 DATA 段共享），未分配则新建并清零
4. **栈构造**：按 RISC-V ABI 约定构造 argc/argv，注意 16 字节对齐
5. **地址空间切换**：在拷贝用户栈参数前必须先切换页表（`lsatp`）
6. **错误清理**：已切换页表后出错，必须先切回内核页表再释放资源

## 六、扩展练习 Challenge1：UNIX PIPE 机制设计方案

### 1. 设计目标与语义

#### 1.1 PIPE 基本语义

在 ucore 中实现 UNIX 管道（Pipe）机制，需要满足以下语义：

- **匿名管道**：`pipe(int fd[2])` 创建一个管道，返回两个文件描述符：
  - `fd[0]`：读端（只能读取）
  - `fd[1]`：写端（只能写入）
- **单向字节流**：数据从写端流向读端，FIFO（先进先出）顺序
- **有界缓冲区**：固定大小的环形缓冲区（如 4096 字节）
- **阻塞语义**：
  - 读端：缓冲区为空时阻塞，直到有数据或写端全关闭（返回 EOF）
  - 写端：缓冲区满时阻塞，直到有空间或读端全关闭（返回 EPIPE 错误）
- **引用计数**：支持 `fork/dup/close`，多个进程可共享同一管道

#### 1.2 典型使用场景

```c
// 父进程创建管道，fork 后父子通过管道通信
int pipefd[2];
pipe(pipefd);

if (fork() == 0) {
    // 子进程：关闭读端，向写端写入数据
    close(pipefd[0]);
    write(pipefd[1], "hello", 5);
    close(pipefd[1]);
    exit(0);
} else {
    // 父进程：关闭写端，从读端读取数据
    close(pipefd[1]);
    char buf[10];
    int n = read(pipefd[0], buf, 10);
    close(pipefd[0]);
}
```

### 2. 数据结构设计

#### 2.1 核心数据结构

```c
#define PIPE_BUF 4096  // 管道缓冲区大小（与 PAGE_SIZE 一致）

// 管道结构体（内核对象）
struct pipe {
    // ========== 同步互斥机制 ==========
    semaphore_t mutex;        // 互斥锁：保护管道状态（rpos/wpos/data/readers/writers）
    wait_queue_t read_wait;   // 读者等待队列：缓冲区为空时读者在此睡眠
    wait_queue_t write_wait;  // 写者等待队列：缓冲区满时写者在此睡眠

    // ========== 环形缓冲区 ==========
    uint8_t  buffer[PIPE_BUF]; // 数据缓冲区
    size_t   read_pos;         // 读位置（0 到 PIPE_BUF-1，循环使用）
    size_t   write_pos;        // 写位置（0 到 PIPE_BUF-1，循环使用）
    size_t   data_len;         // 当前缓冲区有效字节数（0 到 PIPE_BUF）

    // ========== 引用计数 ==========
    int      n_readers;        // 读端打开次数（通过 fd[0] 或其 dup 副本）
    int      n_writers;        // 写端打开次数（通过 fd[1] 或其 dup 副本）

    // ========== 状态标志 ==========
    bool     closed;           // 管道是否已关闭（两端都关闭时释放）
};

// VFS inode 类型扩展（将管道集成到 VFS 层）
#define S_IFIFO  0x1000  // FIFO（管道）类型标志

// 管道 inode（继承 VFS inode）
struct pipe_inode {
    struct inode *vfs_inode;  // VFS 通用 inode
    struct pipe *pipe;        // 指向实际的管道对象
};
```

#### 2.2 与 VFS 的集成

管道作为一种特殊文件，需要在 VFS 层注册对应的 inode 操作：

```c
// 管道的 inode 操作函数表
static const struct inode_ops pipe_inode_ops = {
    .vop_magic   = VOP_MAGIC,
    .vop_open    = pipe_open,
    .vop_close   = pipe_close,
    .vop_read    = pipe_read,
    .vop_write   = pipe_write,
    .vop_fstat   = pipe_fstat,
    // 管道不支持 seek/truncate/lookup 等操作
};
```

### 3. 接口设计

#### 3.1 系统调用接口

```c
// 创建管道（用户态接口）
int sys_pipe(int *fds) {
    // 参数：fds 是用户空间指针，指向 int[2] 数组
    // 返回值：成功返回 0，失败返回负错误码
    // 功能：
    // 1. 分配管道对象（struct pipe）
    // 2. 创建两个 file 对象：一个只读（fds[0]），一个只写（fds[1]）
    // 3. 在当前进程的 files_struct 中分配两个 fd，指向这两个 file
    // 4. 将 fd 拷贝回用户空间
}
```

#### 3.2 核心操作实现（伪代码）

##### 3.2.1 创建管道

```c
int do_pipe(int *fd_store) {
    struct pipe *p;
    struct inode *inode[2];
    struct file *file[2];
    int fd[2];
    int ret;

    // 1. 分配管道对象
    if ((p = kmalloc(sizeof(struct pipe))) == NULL) {
        return -E_NO_MEM;
    }

    // 2. 初始化管道
    memset(p, 0, sizeof(struct pipe));
    sem_init(&p->mutex, 1);
    wait_queue_init(&p->read_wait);
    wait_queue_init(&p->write_wait);
    p->read_pos = p->write_pos = p->data_len = 0;
    p->n_readers = p->n_writers = 1;  // 初始各一个读者和写者
    p->closed = false;

    // 3. 创建两个 inode（类型为 FIFO）
    for (int i = 0; i < 2; i++) {
        if ((inode[i] = alloc_inode(pipe_inode)) == NULL) {
            goto failed;
        }
        vop_init(inode[i], &pipe_inode_ops, NULL);
        vop_info(inode[i], pipe_inode)->pipe = p;
    }

    // 4. 创建两个 file 对象
    if ((ret = file_create(inode[0], O_RDONLY, &file[0])) != 0 ||
        (ret = file_create(inode[1], O_WRONLY, &file[1])) != 0) {
        goto failed;
    }

    // 5. 分配两个 fd
    if ((ret = fd_array_alloc(current->files, file[0], &fd[0])) != 0 ||
        (ret = fd_array_alloc(current->files, file[1], &fd[1])) != 0) {
        goto failed;
    }

    // 6. 返回 fd
    fd_store[0] = fd[0];
    fd_store[1] = fd[1];
    return 0;

failed:
    // 错误处理：释放已分配的资源
    // ...
    return ret;
}
```

##### 3.2.2 读取管道

```c
ssize_t pipe_read(struct inode *node, struct iobuf *iob) {
    struct pipe *p = vop_info(node, pipe_inode)->pipe;
    size_t to_read = iob->io_resid;
    size_t read_total = 0;
    int ret = 0;

    // 1. 获取管道互斥锁
    down(&p->mutex);

    while (to_read > 0) {
        // 2. 检查是否有数据可读
        if (p->data_len > 0) {
            // 有数据：计算可读字节数（考虑环形缓冲区）
            size_t can_read = (p->data_len < to_read) ? p->data_len : to_read;
            size_t first_part = PIPE_BUF - p->read_pos;  // 到缓冲区末尾的字节数

            if (first_part >= can_read) {
                // 数据连续，一次拷贝
                memcpy(iob->io_base, p->buffer + p->read_pos, can_read);
            } else {
                // 数据跨越缓冲区边界，分两次拷贝
                memcpy(iob->io_base, p->buffer + p->read_pos, first_part);
                memcpy(iob->io_base + first_part, p->buffer, can_read - first_part);
            }

            // 更新缓冲区状态
            p->read_pos = (p->read_pos + can_read) % PIPE_BUF;
            p->data_len -= can_read;
            read_total += can_read;
            to_read -= can_read;
            iob->io_base += can_read;

            // 唤醒等待的写者（缓冲区有空间了）
            wakeup_queue(&p->write_wait);
        }
        // 3. 缓冲区为空
        else {
            // 3.1 如果写端已全部关闭，返回 EOF
            if (p->n_writers == 0) {
                break;  // 返回已读取的字节数（可能为 0）
            }

            // 3.2 写端还在，需要等待数据
            if (read_total > 0) {
                break;  // 已经读到一些数据，先返回（避免死锁）
            }

            // 3.3 一个字节都没读到，进入睡眠
            wait_t __wait, *wait = &__wait;
            wait_init(wait, current);
            wait_queue_add(&p->read_wait, wait);
            current->state = PROC_SLEEPING;
            current->wait_state = WT_PIPE;

            // 释放锁并切换进程（睡眠）
            up(&p->mutex);
            schedule();

            // 被唤醒后重新获取锁
            down(&p->mutex);
            wait_queue_del(&p->read_wait, wait);

            // 检查是否被中断（信号）
            if (current->flags & PF_EXITING) {
                ret = -E_INTR;
                break;
            }
        }
    }

    up(&p->mutex);
    iobuf_skip(iob, read_total);
    return (ret == 0) ? read_total : ret;
}
```

##### 3.2.3 写入管道

```c
ssize_t pipe_write(struct inode *node, struct iobuf *iob) {
    struct pipe *p = vop_info(node, pipe_inode)->pipe;
    size_t to_write = iob->io_resid;
    size_t written_total = 0;
    int ret = 0;

    down(&p->mutex);

    // 1. 检查读端是否已全部关闭
    if (p->n_readers == 0) {
        up(&p->mutex);
        return -E_PIPE;  // UNIX 中返回 EPIPE 并发送 SIGPIPE 信号
    }

    while (to_write > 0) {
        // 2. 检查缓冲区是否有空间
        size_t free_space = PIPE_BUF - p->data_len;
        if (free_space > 0) {
            // 有空间：计算可写字节数
            size_t can_write = (free_space < to_write) ? free_space : to_write;
            size_t first_part = PIPE_BUF - p->write_pos;

            if (first_part >= can_write) {
                memcpy(p->buffer + p->write_pos, iob->io_base, can_write);
            } else {
                memcpy(p->buffer + p->write_pos, iob->io_base, first_part);
                memcpy(p->buffer, iob->io_base + first_part, can_write - first_part);
            }

            // 更新缓冲区状态
            p->write_pos = (p->write_pos + can_write) % PIPE_BUF;
            p->data_len += can_write;
            written_total += can_write;
            to_write -= can_write;
            iob->io_base += can_write;

            // 唤醒等待的读者
            wakeup_queue(&p->read_wait);
        }
        // 3. 缓冲区满，需要等待
        else {
            if (written_total > 0) {
                break;  // 已写入一些数据，先返回
            }

            // 进入睡眠等待读者腾出空间
            wait_t __wait, *wait = &__wait;
            wait_init(wait, current);
            wait_queue_add(&p->write_wait, wait);
            current->state = PROC_SLEEPING;
            current->wait_state = WT_PIPE;

            up(&p->mutex);
            schedule();
            down(&p->mutex);
            wait_queue_del(&p->write_wait, wait);

            // 重新检查读端是否关闭
            if (p->n_readers == 0) {
                ret = -E_PIPE;
                break;
            }

            if (current->flags & PF_EXITING) {
                ret = -E_INTR;
                break;
            }
        }
    }

    up(&p->mutex);
    iobuf_skip(iob, written_total);
    return (ret == 0) ? written_total : ret;
}
```

##### 3.2.4 关闭管道

```c
int pipe_close(struct inode *node, uint32_t open_flags) {
    struct pipe *p = vop_info(node, pipe_inode)->pipe;

    down(&p->mutex);

    // 1. 根据打开标志递减引用计数
    if (open_flags & O_RDONLY) {
        p->n_readers--;
        // 读端关闭，唤醒等待的写者（让其收到 EPIPE 错误）
        if (p->n_readers == 0) {
            wakeup_queue(&p->write_wait);
        }
    }
    if (open_flags & O_WRONLY) {
        p->n_writers--;
        // 写端关闭，唤醒等待的读者（让其读到 EOF）
        if (p->n_writers == 0) {
            wakeup_queue(&p->read_wait);
        }
    }

    // 2. 如果两端都已关闭，释放管道对象
    bool should_free = (p->n_readers == 0 && p->n_writers == 0);
    up(&p->mutex);

    if (should_free) {
        kfree(p);
    }

    return 0;
}
```

### 4. 同步互斥处理详解

#### 4.1 关键并发问题

| 并发场景 | 问题描述 | 解决方案 |
|---------|---------|---------|
| **多读者并发** | 多个进程同时从管道读取，可能导致 `read_pos` 更新混乱 | 使用 `mutex` 互斥锁，整个读操作原子化 |
| **多写者并发** | 多个进程同时写入，可能导致数据交错 | 同上，写操作也需持锁 |
| **读写并发** | 读者读取时写者同时写入，缓冲区状态不一致 | `mutex` 保护 `data_len/read_pos/write_pos` |
| **阻塞唤醒竞态** | 检查条件后、睡眠前被唤醒，导致信号丢失 | 在持锁状态下检查条件并加入等待队列，释放锁后立即 `schedule()` |
| **关闭并发** | 读写时管道被关闭 | `n_readers/n_writers` 递减前需持锁，并唤醒对端 |

#### 4.2 死锁避免

**场景**：单进程同时持有读端和写端，自己读自己写可能死锁

**解决**：
- 读操作：读到任意数据后立即返回，不等待填满缓冲区
- 写操作：写入任意数据后立即返回，不等待全部写完
- 避免在持锁状态下进行长时间阻塞操作

#### 4.3 引用计数管理

```c
// fork 时：父子进程共享管道，引用计数需增加
int copy_pipe(struct file *src, struct file *dst) {
    struct pipe *p = vop_info(src->node, pipe_inode)->pipe;
    down(&p->mutex);
    if (src->readable) p->n_readers++;
    if (src->writable) p->n_writers++;
    up(&p->mutex);
    // ... 拷贝 file 结构
}

// dup 时：同上
int dup_pipe(int oldfd, int newfd) {
    // 类似 copy_pipe，增加引用计数
}
```

### 5. 测试用例设计

```c
// 测试1：基本读写
void test_pipe_basic() {
    int pipefd[2];
    pipe(pipefd);
    write(pipefd[1], "hello", 5);
    char buf[10];
    int n = read(pipefd[0], buf, 10);
    assert(n == 5 && memcmp(buf, "hello", 5) == 0);
    close(pipefd[0]);
    close(pipefd[1]);
}

// 测试2：阻塞语义
void test_pipe_block() {
    int pipefd[2];
    pipe(pipefd);
    if (fork() == 0) {
        close(pipefd[0]);
        sleep(1000);  // 延迟写入
        write(pipefd[1], "data", 4);
        exit(0);
    } else {
        close(pipefd[1]);
        char buf[10];
        // 此处会阻塞，直到子进程写入数据
        int n = read(pipefd[0], buf, 10);
        assert(n == 4);
    }
}

// 测试3：EOF 语义
void test_pipe_eof() {
    int pipefd[2];
    pipe(pipefd);
    close(pipefd[1]);  // 关闭写端
    char buf[10];
    int n = read(pipefd[0], buf, 10);  // 应立即返回 0
    assert(n == 0);  // EOF
}

// 测试4：EPIPE 错误
void test_pipe_epipe() {
    int pipefd[2];
    pipe(pipefd);
    close(pipefd[0]);  // 关闭读端
    int ret = write(pipefd[1], "data", 4);  // 应返回 -E_PIPE
    assert(ret == -E_PIPE);
}
```

## 七、扩展练习 Challenge2：软链接与硬链接机制设计方案

### 1. 设计目标与语义

#### 1.1 硬链接（Hard Link）

**基本概念**：
- 硬链接是指多个目录项（directory entry）指向同一个 inode
- 所有硬链接共享同一份数据（同一个 inode，同一组数据块）
- 修改任意一个硬链接的内容，其他硬链接也会看到变化

**语义要求**：
```c
// 创建硬链接
int link(const char *oldpath, const char *newpath);
// 功能：在 newpath 位置创建一个新的目录项，指向 oldpath 的 inode
// 结果：inode->nlinks++（链接计数增加）

// 删除链接
int unlink(const char *path);
// 功能：删除 path 对应的目录项
// 结果：inode->nlinks--（链接计数减少）
// 特殊：当 nlinks==0 且无进程打开该文件时，释放 inode 和数据块
```

**限制**：
- 不允许对目录创建硬链接（防止目录树出现环）
- 不允许跨文件系统硬链接（不同文件系统的 inode 编号空间独立）

#### 1.2 软链接（Symbolic Link/Symlink）

**基本概念**：
- 软链接是一个特殊类型的文件，其内容是目标路径的字符串
- 软链接有自己独立的 inode（与目标文件不同）
- 访问软链接时，VFS 会自动读取目标路径并跳转

**语义要求**：
```c
// 创建软链接
int symlink(const char *target, const char *linkpath);
// 功能：创建一个新 inode（类型为 SYMLINK），内容为 target 字符串

// 读取软链接目标
ssize_t readlink(const char *linkpath, char *buf, size_t bufsz);
// 功能：读取软链接文件的内容（目标路径字符串）

// 不跟随软链接的 stat
int lstat(const char *path, struct stat *st);
// 功能：返回软链接本身的属性，而不是目标文件的属性
```

**特性**：
- 允许跨文件系统（target 只是字符串）
- 允许指向目录
- 允许指向不存在的路径（悬空链接，dangling symlink）
- 路径解析时默认跟随软链接，需要防止循环（最大深度限制）

### 2. 数据结构设计

#### 2.1 SFS inode 扩展

```c
// SFS disk inode 结构（已有字段）
struct sfs_disk_inode {
    uint32_t size;               // 文件大小
    uint16_t type;               // 文件类型
    uint16_t nlinks;             // 硬链接计数（已有，直接复用）
    uint32_t blocks;             // 数据块数量
    uint32_t direct[SFS_NDIRECT];   // 直接索引
    uint32_t indirect;           // 间接索引
};

// 扩展文件类型定义
#define SFS_TYPE_FILE     0x001  // 普通文件（已有）
#define SFS_TYPE_DIR      0x002  // 目录（已有）
#define SFS_TYPE_SYMLINK  0x003  // 软链接（新增）

// 软链接的数据存储：
// - type = SFS_TYPE_SYMLINK
// - size = 目标路径字符串长度（包含 '\0'）
// - 目标路径字符串存储在数据块中（复用 direct/indirect 索引）
```

#### 2.2 VFS 层扩展

```c
// VFS inode 类型标志（stat.st_mode 字段）
#define S_IFLNK  0xA000   // 软链接类型（与 UNIX 一致）

// VFS inode 操作函数表扩展
struct inode_ops {
    // ... 现有操作 ...

    // 硬链接操作
    int (*vop_link)(struct inode *dir, const char *name, struct inode *target);
    int (*vop_unlink)(struct inode *dir, const char *name);

    // 软链接操作
    int (*vop_symlink)(struct inode *dir, const char *name, const char *target);
    ssize_t (*vop_readlink)(struct inode *node, struct iobuf *iob);
};
```

#### 2.3 路径解析上下文

```c
// 路径解析时需要跟踪软链接跟随深度
#define MAX_SYMLINK_DEPTH 8  // 最大软链接跟随深度（防止循环）

struct lookup_context {
    int symlink_depth;        // 当前软链接跟随深度
    bool follow_last_symlink; // 是否跟随路径最后一个组件的软链接
                             // open/stat: true; lstat/readlink: false
};
```

### 3. 接口设计

#### 3.1 系统调用接口

```c
// 硬链接系统调用
int sys_link(const char *oldpath, const char *newpath);
int sys_unlink(const char *path);

// 软链接系统调用
int sys_symlink(const char *target, const char *linkpath);
ssize_t sys_readlink(const char *linkpath, char *buf, size_t bufsz);

// 不跟随软链接的 stat
int sys_lstat(const char *path, struct stat *st);
```

#### 3.2 核心操作实现（伪代码）

##### 3.2.1 创建硬链接

```c
int sys_link(const char *oldpath, const char *newpath) {
    struct inode *old_inode, *new_dir;
    char *name;
    int ret;

    // 1. 解析 oldpath，获取目标 inode（跟随软链接）
    if ((ret = vfs_lookup(oldpath, &old_inode)) != 0) {
        return ret;
    }

    // 2. 检查目标文件类型：不允许对目录创建硬链接
    uint32_t type;
    vop_gettype(old_inode, &type);
    if (S_ISDIR(type)) {
        vop_ref_dec(old_inode);
        return -E_ISDIR;  // 不允许硬链接目录
    }

    // 3. 解析 newpath 的父目录（不跟随最后一个组件的软链接）
    if ((ret = vfs_lookup_parent(newpath, &new_dir, &name)) != 0) {
        vop_ref_dec(old_inode);
        return ret;
    }

    // 4. 在父目录中创建新的目录项，指向 old_inode
    lock_inode(new_dir);
    {
        // 检查 newpath 是否已存在
        struct inode *existing;
        if (vfs_lookup_once(new_dir, name, &existing) == 0) {
            vop_ref_dec(existing);
            ret = -E_EXISTS;
            goto out;
        }

        // 在目录中添加新目录项（dirent）
        ret = sfs_dirent_create(new_dir, name, old_inode->ino);
        if (ret != 0) {
            goto out;
        }

        // 增加 inode 的硬链接计数
        lock_inode(old_inode);
        vop_info(old_inode, sfs_inode)->din->nlinks++;
        vop_info(old_inode, sfs_inode)->dirty = 1;
        unlock_inode(old_inode);
    }
out:
    unlock_inode(new_dir);
    vop_ref_dec(old_inode);
    vop_ref_dec(new_dir);
    return ret;
}
```

##### 3.2.2 删除链接（unlink）

```c
int sys_unlink(const char *path) {
    struct inode *dir, *target_inode;
    char *name;
    int ret;

    // 1. 解析父目录（不跟随最后一个组件的软链接）
    if ((ret = vfs_lookup_parent(path, &dir, &name)) != 0) {
        return ret;
    }

    // 2. 在父目录中查找目标目录项
    lock_inode(dir);
    {
        int slot;
        if ((ret = sfs_dirent_search(dir, name, &target_inode, &slot)) != 0) {
            unlock_inode(dir);
            vop_ref_dec(dir);
            return ret;  // 文件不存在
        }

        // 3. 检查是否为目录：unlink 不能删除目录（需用 rmdir）
        uint32_t type;
        vop_gettype(target_inode, &type);
        if (S_ISDIR(type)) {
            ret = -E_ISDIR;
            goto out;
        }

        // 4. 删除目录项
        ret = sfs_dirent_delete(dir, slot);
        if (ret != 0) {
            goto out;
        }

        // 5. 递减 inode 的硬链接计数
        lock_inode(target_inode);
        struct sfs_disk_inode *din = vop_info(target_inode, sfs_inode)->din;
        assert(din->nlinks > 0);
        din->nlinks--;
        vop_info(target_inode, sfs_inode)->dirty = 1;

        // 6. 如果 nlinks == 0 且无进程打开，释放 inode
        if (din->nlinks == 0 && inode_ref_count(target_inode) == 1) {
            // 释放数据块
            sfs_truncate_inode(target_inode, 0);
            // 释放 inode 本身（在 vop_ref_dec 中完成）
        }
        unlock_inode(target_inode);
    }
out:
    unlock_inode(dir);
    vop_ref_dec(target_inode);
    vop_ref_dec(dir);
    return ret;
}
```

##### 3.2.3 创建软链接

```c
int sys_symlink(const char *target, const char *linkpath) {
    struct inode *dir, *symlink_inode;
    char *name;
    int ret;

    // 1. 解析 linkpath 的父目录
    if ((ret = vfs_lookup_parent(linkpath, &dir, &name)) != 0) {
        return ret;
    }

    lock_inode(dir);
    {
        // 2. 检查 linkpath 是否已存在
        struct inode *existing;
        if (vfs_lookup_once(dir, name, &existing) == 0) {
            vop_ref_dec(existing);
            ret = -E_EXISTS;
            goto out;
        }

        // 3. 创建新 inode（类型为 SYMLINK）
        struct sfs_disk_inode din;
        memset(&din, 0, sizeof(din));
        din.type = SFS_TYPE_SYMLINK;
        din.nlinks = 1;
        din.size = strlen(target) + 1;  // 包含 '\0'

        uint32_t ino;
        if ((ret = sfs_alloc_inode(dir->fs, &din, &ino, &symlink_inode)) != 0) {
            goto out;
        }

        // 4. 将 target 字符串写入 inode 的数据块
        struct iobuf iob;
        iobuf_init(&iob, (void *)target, din.size, 0);
        vop_write(symlink_inode, &iob);

        // 5. 在父目录中添加目录项
        ret = sfs_dirent_create(dir, name, ino);
        vop_ref_dec(symlink_inode);
    }
out:
    unlock_inode(dir);
    vop_ref_dec(dir);
    return ret;
}
```

##### 3.2.4 读取软链接

```c
ssize_t sys_readlink(const char *linkpath, char *buf, size_t bufsz) {
    struct inode *symlink_inode;
    int ret;

    // 1. 解析 linkpath（不跟随软链接！）
    struct lookup_context ctx = { .follow_last_symlink = false };
    if ((ret = vfs_lookup_ex(linkpath, &symlink_inode, &ctx)) != 0) {
        return ret;
    }

    // 2. 检查是否为软链接
    uint32_t type;
    vop_gettype(symlink_inode, &type);
    if (!S_ISLNK(type)) {
        vop_ref_dec(symlink_inode);
        return -E_INVAL;  // 不是软链接
    }

    // 3. 读取软链接的内容（target 字符串）
    struct iobuf iob;
    iobuf_init(&iob, buf, bufsz, 0);
    ret = vop_read(symlink_inode, &iob);
    vop_ref_dec(symlink_inode);

    // 4. 返回读取的字节数（注意：Linux 的 readlink 不会添加 '\0'）
    return ret;
}
```

##### 3.2.5 路径解析（支持软链接跟随）

```c
int vfs_lookup_ex(const char *path, struct inode **node_store,
                  struct lookup_context *ctx) {
    struct inode *node = root_inode;
    char name[FS_MAX_FNAME_LEN + 1];
    int ret;

    vop_ref_inc(node);

    // 逐个组件解析路径
    while (*path != '\0') {
        // 跳过路径分隔符
        while (*path == '/') path++;
        if (*path == '\0') break;

        // 提取当前组件名
        extract_component(path, name, &path);

        // 在当前目录中查找
        struct inode *next;
        if ((ret = vop_lookup(node, name, &next)) != 0) {
            vop_ref_dec(node);
            return ret;
        }

        vop_ref_dec(node);
        node = next;

        // 检查是否为软链接
        uint32_t type;
        vop_gettype(node, &type);
        if (S_ISLNK(type)) {
            // 判断是否需要跟随软链接
            bool is_last_component = (*path == '\0');
            if (!is_last_component || ctx->follow_last_symlink) {
                // 防止无限循环
                if (++ctx->symlink_depth > MAX_SYMLINK_DEPTH) {
                    vop_ref_dec(node);
                    return -E_LOOP;  // 软链接层数过深
                }

                // 读取目标路径
                char target[FS_MAX_FPATH_LEN];
                struct iobuf iob;
                iobuf_init(&iob, target, sizeof(target), 0);
                vop_read(node, &iob);
                vop_ref_dec(node);

                // 递归解析目标路径
                if ((ret = vfs_lookup_ex(target, &node, ctx)) != 0) {
                    return ret;
                }
            }
        }
    }

    *node_store = node;
    return 0;
}
```

### 4. 同步互斥处理详解

#### 4.1 关键并发问题

| 并发场景 | 问题描述 | 解决方案 |
|---------|---------|---------|
| **link/unlink 并发** | 同时创建和删除同一文件的硬链接，`nlinks` 可能不一致 | 使用 inode 锁保护 `nlinks` 的更新 |
| **unlink 与 open 并发** | unlink 删除最后一个链接时，另一进程正在打开该文件 | 区分 `nlinks`（硬链接数）和 `ref_count`（打开次数），两者都为 0 才释放 |
| **目录操作并发** | 多进程同时在同一目录中创建/删除目录项 | 使用目录 inode 锁保护目录操作 |
| **软链接循环** | `a -> b -> a` 导致路径解析无限循环 | 使用 `symlink_depth` 限制最大跟随深度（MAX_SYMLINK_DEPTH = 8） |
| **软链接目标变化** | 解析软链接时目标文件被删除或修改 | 路径解析过程中持有 inode 引用，防止被释放 |

#### 4.2 加锁顺序（避免死锁）

**规则**：始终按固定顺序获取锁

```c
// 1. 目录层级顺序：先锁父目录，再锁子目录/文件
lock_inode(parent_dir);
lock_inode(child_inode);

// 2. inode 号顺序：对于同级目录项，按 ino 大小顺序加锁
if (inode1->ino < inode2->ino) {
    lock_inode(inode1);
    lock_inode(inode2);
} else {
    lock_inode(inode2);
    lock_inode(inode1);
}
```

#### 4.3 引用计数管理

```c
struct sfs_inode {
    struct sfs_disk_inode *din;  // 磁盘 inode（包含 nlinks）
    int reclaim_count;            // VFS 引用计数（进程打开次数）
    // ...
};

// 释放 inode 的条件
bool should_free_inode(struct sfs_inode *sin) {
    // 两个条件都满足才释放：
    // 1. 硬链接计数为 0（所有目录项都已删除）
    // 2. 引用计数为 0（没有进程打开该文件）
    return (sin->din->nlinks == 0 && sin->reclaim_count == 0);
}
```

#### 4.4 一致性保证

**原子性操作序列**：

```c
// link 操作：目录项创建 + nlinks 增加必须原子
lock_inode(dir);
lock_inode(target);
{
    sfs_dirent_create(dir, name, target->ino);  // 步骤1
    target->nlinks++;                           // 步骤2
    mark_dirty(dir);
    mark_dirty(target);
}
unlock_inode(target);
unlock_inode(dir);

// unlink 操作：目录项删除 + nlinks 减少必须原子
lock_inode(dir);
lock_inode(target);
{
    sfs_dirent_delete(dir, name);  // 步骤1
    target->nlinks--;               // 步骤2
    if (target->nlinks == 0 && target->ref_count == 0) {
        free_inode_data(target);   // 步骤3（条件执行）
    }
    mark_dirty(dir);
    mark_dirty(target);
}
unlock_inode(target);
unlock_inode(dir);
```

### 5. 测试用例设计

```c
// 测试1：硬链接基本功能
void test_hardlink_basic() {
    // 创建文件并写入内容
    int fd = open("/test.txt", O_CREAT | O_WRONLY);
    write(fd, "hello", 5);
    close(fd);

    // 创建硬链接
    link("/test.txt", "/test_link.txt");

    // 通过链接读取，应看到相同内容
    fd = open("/test_link.txt", O_RDONLY);
    char buf[10];
    read(fd, buf, 5);
    assert(memcmp(buf, "hello", 5) == 0);
    close(fd);

    // 删除原文件，链接仍可访问
    unlink("/test.txt");
    fd = open("/test_link.txt", O_RDONLY);
    assert(fd >= 0);
    close(fd);

    unlink("/test_link.txt");
}

// 测试2：软链接基本功能
void test_symlink_basic() {
    // 创建目标文件
    int fd = open("/target.txt", O_CREAT | O_WRONLY);
    write(fd, "data", 4);
    close(fd);

    // 创建软链接
    symlink("/target.txt", "/link.txt");

    // 通过软链接访问
    fd = open("/link.txt", O_RDONLY);
    char buf[10];
    read(fd, buf, 4);
    assert(memcmp(buf, "data", 4) == 0);
    close(fd);

    // 读取软链接目标
    char target[100];
    int n = readlink("/link.txt", target, 100);
    assert(n == 11 && memcmp(target, "/target.txt", 11) == 0);

    // 删除目标文件，软链接变为悬空
    unlink("/target.txt");
    fd = open("/link.txt", O_RDONLY);
    assert(fd < 0);  // 打开失败

    unlink("/link.txt");
}

// 测试3：软链接循环检测
void test_symlink_loop() {
    symlink("/link2", "/link1");
    symlink("/link1", "/link2");

    // 尝试访问，应返回 -E_LOOP
    int fd = open("/link1", O_RDONLY);
    assert(fd == -E_LOOP);

    unlink("/link1");
    unlink("/link2");
}

// 测试4：unlink 与 open 并发
void test_unlink_open_concurrent() {
    int fd = open("/test.txt", O_CREAT | O_WRONLY);
    write(fd, "hello", 5);
    // 不关闭 fd，文件仍被打开

    // 删除文件（nlinks = 0）
    unlink("/test.txt");

    // 通过已打开的 fd 仍可访问（ref_count > 0）
    char buf[10];
    lseek(fd, 0, SEEK_SET);
    read(fd, buf, 5);
    assert(memcmp(buf, "hello", 5) == 0);

    // 关闭 fd 后，inode 才真正释放
    close(fd);
}
```

## 八、本实验重要知识点与 OS 原理对应

- VFS 抽象：用统一 inode/file 接口屏蔽不同文件系统差异（对应“分层抽象”思想）
- inode/dirent：目录项到 inode 的映射、inode 内保存数据块索引（对应“索引分配/索引节点”）
- 文件描述符与打开文件表：进程内 fd → file → inode（对应“进程资源表/引用计数”）
- exec 机制：建立新 mm、加载 ELF 段、构造用户栈与 trapframe（对应“程序装载/地址空间切换/特权级切换”）
- pipe/链接：分别对应 IPC（生产者消费者同步）与文件系统命名/引用模型（引用计数与路径解析）

## 九、OS 原理中重要但实验未覆盖的点（举例）

- 缓冲区缓存/页缓存（buffer cache / page cache）与写回策略（write-back）
- 崩溃一致性与日志文件系统（journaling）、事务/检查点
- 完整的权限模型（UID/GID/ACL）、挂载与命名空间
- 更复杂的 IPC（socket、匿名/命名管道、epoll/select 等）
