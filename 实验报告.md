# Lab8 文件系统实验报告

- 学号：2310675
- 实验：Lab 8 文件系统（VFS + SFS + 基于文件系统的 exec）
- 代码目录：`lab8/`

## 一、实验目标与完成情况

本实验在 ucore 内核中引入文件系统支持，并在此基础上实现：

- VFS 抽象层的文件访问路径（open/read/write/close/seek 等）
- SFS（Simple FS）基于 inode 的文件组织与数据块读写
- “一切皆文件”的设备文件（如 `stdin:`/`stdout:`）
- 基于文件系统的程序加载与执行（`exec` 从磁盘文件加载 ELF）

本次完成内容：

- 练习1：实现 `sfs_io_nolock()` 的文件读写逻辑
- 练习2：实现基于文件系统的 `load_icode()`，并补全 `proc_run/do_fork/alloc_proc` 相关改动
- Challenge1/Challenge2：给出 PIPE / 软硬链接机制设计方案（语义 + 数据结构 + 接口 + 同步互斥）

### 代码修改摘要（对应 LAB8 标注处）

- `lab8/kern/fs/sfs/sfs_inode.c`：补全 `sfs_io_nolock()`（LAB8:EXERCISE1）
- `lab8/kern/process/proc.c`：
  - `alloc_proc()` 初始化 `proc->filesp`
  - `proc_run()` 切换页表并 `flush_tlb()`
  - `do_fork()` 增加 `copy_files()` 及错误清理（LAB8:EXERCISE2）
  - `load_icode()`：从 fd 读取 ELF 并加载到新 mm（LAB8:EXERCISE2）
- `lab8/kern/schedule/default_sched_stride.c`：将 LAB6 “YOUR CODE”标注替换为学号（保持原有实现）
- `lab8/kern/mm/pmm.c`：补全 `copy_range()`（来自 LAB5 的页复制 + 映射），保证 `fork()` 后子进程能正常执行（否则会出现 Instruction page fault）
- `lab8/kern/trap/trap.c`：完善页故障输出与处理：打印 `epc/tval` 并在用户态故障时退出进程，避免无限刷屏
- `lab8/user/badsegment.c` / `lab8/user/faultread.c` / `lab8/user/faultreadkernel.c` / `lab8/user/testbss.c`：改为“fork + wait 自检”形式：子进程触发异常应被内核杀死，父进程验证退出码并打印 `pass`，避免在 `sh` 中显示 `error: -9 - process is killed`

## 二、实验环境与运行验证

- 在 `lab8/` 下编译：`make -j4`
- 运行：`make qemu`
- 进入用户态 `sh` 后，可执行（示例）：`hello`、`exit` 等 SFS 中的用户程序
- `fork()`/`exec()` 验证：在 `sh` 内运行任意外部命令会触发 `fork()`（如 `hello`/`sleep`/`forktest`），应能正常运行并回到 shell
- 异常验证：`faultread`/`badsegment` 等程序触发页故障时，应打印一次故障信息并退出回到 shell（不应无限刷屏）

## 三、练习0：填写已有实验

实验指导书要求将 LAB2~LAB7 已完成内容合入 LAB8。为保证 LAB8 能独立编译与运行，需要满足以下“最低可用”条件：

- 进程管理、虚拟内存管理等（LAB2~LAB5）可用，能创建进程并切换上下文
- `fork()` 依赖 LAB5 的 `copy_range()`：需要能把父进程的用户态页内容复制到子进程并建立映射，否则子进程返回用户态会立刻触发 Instruction page fault
- 文件系统相关新增字段（`proc_struct::filesp`）在进程创建/复制时正确初始化与复制
- 调度、同步相关（LAB6/LAB7）即使未深度扩展，也应保证不影响 LAB8 的文件系统与 `exec` 主流程

本次 LAB8 代码中涉及 LAB6/LAB7 的部分以“可编译可运行”为目标，LAB8 的关键功能不依赖 Challenge 的扩展实现。

## 四、练习1：完成读文件操作 `sfs_io_nolock()`（需要编码）

### 1. 目标与位置

目标：实现 SFS 文件（非目录）在指定 `offset` 上的读/写，将磁盘数据块与内存缓冲区互相搬运，并返回真实读写长度。

位置：`lab8/kern/fs/sfs/sfs_inode.c` 中 `sfs_io_nolock()`。

### 2. 核心思路（三段式 I/O）

`sfs_io_nolock()` 的关键是把“任意偏移 + 任意长度”的读写拆成三段：

1. **首块非对齐部分**：`offset` 若不在块边界上，用 `sfs_rbuf/sfs_wbuf` 对单块做“部分读写”
2. **中间整块部分**：块对齐后，对连续的整块范围用 `sfs_rblock/sfs_wblock` 批量读写
3. **尾块非对齐部分**：`endpos` 若不在块边界上，最后剩余字节再次用 `sfs_rbuf/sfs_wbuf` 处理

其中每次读写前都需要：

- `sfs_bmap_load_nolock(sfs, sin, index, &ino)`：将文件的逻辑块号映射到磁盘块号（必要时创建新块，写入时会发生）
- 根据 `write` 选择 `sfs_buf_op` / `sfs_block_op`（读用 `sfs_rbuf/sfs_rblock`，写用 `sfs_wbuf/sfs_wblock`）

### 3. 关键边界处理

- 对 `offset/endpos` 做越界检查（`offset<0`、超过最大文件大小等）
- 读文件时，若 `offset >= din->size` 直接返回 0；并将 `endpos` 截断到文件大小
- 写文件时，若写入超过原大小，需要在结束时更新 `din->size` 并置 `sin->dirty`

### 4. 与上层调用链的对应关系

以用户态 `read()` 为例，其典型路径为：

`sys_read → sysfile_read → file_read → vop_read → sfs_read → sfs_io → sfs_io_nolock → sfs_rbuf/sfs_rblock → dop_io → ide`

这体现了指导书中强调的分层：用户接口层 → VFS 抽象层 → 具体文件系统（SFS）→ 块设备驱动。

## 五、练习2：完成基于文件系统的执行程序机制（需要编码）

### 1. 目标

将 LAB5 中“从内存镜像加载 ELF”的 `load_icode()` 改为“从文件系统读取 ELF 文件并加载”，使 `exec` 可以执行 SFS 中的用户程序（如 `sh/hello/exit` 等）。

### 2. 相关改动点概述

1. `alloc_proc()`：新增字段 `proc->filesp` 的初始化（进程文件上下文指针）
2. `proc_run()`：切换页表（`lsatp`）后刷新 TLB（`flush_tlb`），避免地址空间切换后使用旧 TLB
3. `do_fork()`：在 fork/clone 时复制或共享父进程文件上下文（`copy_files()`），并补全失败清理路径
4. `load_icode(fd, argc, kargv)`：核心实现
   - 通过 `load_icode_read()` + `sysfile_seek/sysfile_read` 从 fd 读取 ELF header / program header / segment data
   - `mm_create/setup_pgdir/mm_map/pgdir_alloc_page` 构建新 mm、新页表、段映射、用户栈
   - 将 `argc/argv` 按约定压入用户栈，并在 trapframe 中设置 `a0/a1/sp/epc/status`

### 3. `load_icode()` 关键流程（从文件加载 ELF）

1. **创建新 mm 与页表**
   - `mm_create()` 分配并初始化 `mm_struct`
   - `setup_pgdir(mm)` 创建新页表并拷贝内核映射

2. **读取并校验 ELF**
   - 读取 `struct elfhdr`，检查 `e_magic == ELF_MAGIC`

3. **遍历 Program Header 加载段**
   - 只处理 `p_type == ELF_PT_LOAD` 的段
   - `mm_map(mm, p_va, p_memsz, vm_flags)` 建 vma（标记这段虚拟地址合法）
   - 为段中每页分配物理页并建立映射：
     - 文件部分（`p_filesz`）：`load_icode_read(fd, dst, size, offset)` 读入对应页
     - BSS 部分（`p_memsz - p_filesz`）：对剩余范围 `memset(0)`

4. **建立用户栈并放置参数**
   - `mm_map(mm, USTACKTOP-USTACKSIZE, USTACKSIZE, VM_READ|VM_WRITE|VM_STACK, NULL)`
   - 由于本实验中未实现通用缺页异常处理路径，用户栈采用“预分配物理页”方式保证运行期不触发缺页：
     - 至少分配若干页（实现中确保至少 4 页，并覆盖参数占用范围）
   - 在用户栈中写入：
     - `argv` 各字符串内容
     - `argv[]` 指针数组（以用户虚拟地址为元素），末尾 `NULL`
     - 最终在 trapframe 里设置：`a0=argc`，`a1=argv`（用户态指针）

5. **切换到新地址空间并设置 trapframe**
   - `current->mm = mm; current->pgdir = PADDR(mm->pgdir); lsatp(current->pgdir); flush_tlb();`
   - trapframe：
     - `tf->epc = elf.e_entry`
     - `tf->gpr.sp = 用户栈 sp`
     - `tf->status`：清 `SSTATUS_SPP` 使返回到 U-mode，置 `SSTATUS_SPIE` 允许中断

### 4. 错误恢复与资源释放要点

- 任意阶段失败都应按“逆序释放”原则清理：VMA/物理页 → 页表 → mm_struct
- 若已经切换到新页表，则清理前需先切回 `boot_pgdir_pa`，避免在释放页表时 CPU 仍使用它做地址转换

## 六、扩展练习 Challenge1：UNIX PIPE 机制设计方案

### 1. 目标语义（与 UNIX/Linux 对齐）

新增 `pipe()` 后，满足典型 UNIX 语义：

- `pipe(int fd[2])` 创建一个匿名管道，返回两个 fd：`fd[0]` 读端、`fd[1]` 写端
- 管道是 **字节流**、**单向**、**有界缓冲区**（环形队列）
- 读写阻塞语义：
  - 缓冲区为空：`read` 阻塞（若写端全关闭则返回 0 表示 EOF）
  - 缓冲区满：`write` 阻塞（若读端全关闭则返回 `-E_PIPE`/`-E_INVAL` 等，类 UNIX 中为 `EPIPE` 并触发 SIGPIPE）
- 支持 `fork/dup/close`：fd 复制会共享同一个管道对象并维护引用计数

### 2. 数据结构设计（示例 C struct）

建议把 pipe 作为一种“内核对象”，并用 VFS 的 inode/file 抽象对接：

```c
#define PIPE_BUFSZ 4096

typedef struct pipe {
    semaphore_t mutex;         // 互斥访问缓冲区与计数
    wait_queue_t rwait;        // 读等待队列：空时读者睡眠
    wait_queue_t wwait;        // 写等待队列：满时写者睡眠

    uint8_t  buf[PIPE_BUFSZ];  // 环形缓冲区
    size_t   rpos, wpos;       // 读/写位置（mod PIPE_BUFSZ）
    size_t   data;             // 缓冲区内有效字节数（0..PIPE_BUFSZ）

    int      readers;          // 打开读端的引用计数
    int      writers;          // 打开写端的引用计数
} pipe_t;

// 让 VFS 文件对象指向 pipe_t（也可作为一种 inode 类型）
typedef struct pipe_inode {
    struct inode vfs_inode;    // 若 ucore 以 inode 承载操作
    pipe_t *pipe;
} pipe_inode_t;
```

备注：ucore 已提供 `semaphore_t/wait_queue_t`，可以用 `wait_current_set + schedule + wakeup_queue` 组合出条件等待；也可用“计数信号量 + 互斥锁”做生产者/消费者。

### 3. 接口设计（系统调用 + VFS 操作）

系统调用层（用户态接口）：

- `int sys_pipe(int fds[2]);`：创建 pipe，分配两个 fd，并分别绑定“读端 file”与“写端 file”

VFS/文件操作层（语义即可，不必具体实现）：

- `ssize_t pipe_read(struct file *f, void *buf, size_t n);`
  - 若 `data==0 && writers>0`：阻塞等待写者写入
  - 若 `data==0 && writers==0`：返回 0（EOF）
  - 否则从环形缓冲区拷贝 `min(n, data)` 字节
- `ssize_t pipe_write(struct file *f, const void *buf, size_t n);`
  - 若 `readers==0`：返回错误（类 UNIX 为 `EPIPE`）
  - 若缓冲区满：阻塞等待读者读取腾出空间
  - 否则拷贝数据进缓冲区并唤醒读者
- `int pipe_close(struct file *f);`
  - 递减 `readers/writers`，并在“写端归零”时唤醒所有读者（使其读到 EOF）
  - 在“读端归零”时唤醒写者并令其写入失败

### 4. 同步互斥与竞态处理

必须显式处理的并发问题：

- 多读者/多写者同时读写：缓冲区状态（`rpos/wpos/data`）必须互斥更新
- 阻塞与唤醒的竞态：检查条件与入队睡眠需要原子化（典型做法：在持有 mutex 时检查条件，条件不满足则将当前进程加入等待队列并睡眠；被唤醒后再次循环检查条件）
- 关闭与读写并发：`close` 需要与 `read/write` 协同更新 `readers/writers`，并唤醒对端避免永久睡眠

## 七、扩展练习 Challenge2：软链接与硬链接机制设计方案

### 1. 目标语义

**硬链接（hard link）**：

- 多个目录项指向同一个 inode（共享数据块）
- `link(oldpath, newpath)`：在 newpath 所在目录增加一个目录项，其 inode 号与 oldpath 相同，并使 `nlinks++`
- `unlink(path)`：删除目录项，`nlinks--`；当 `nlinks==0` 且无进程打开该文件时释放 inode 与数据块
- 一般不允许对目录创建硬链接（避免目录环）
- 不允许跨文件系统硬链接（`EXDEV`）

**软链接（symbolic link）**：

- 创建一个“链接文件”，其内容保存目标路径字符串
- `symlink(target, linkpath)`：创建 linkpath 作为新 inode（类型为 SYMLINK），写入 target 字符串
- `readlink(linkpath, buf, len)`：读取该链接保存的 target 字符串
- 路径解析时默认“跟随”软链接（`open/stat`），但 `lstat` 不跟随
- 需要有“最大跟随深度”防止循环链接（如 8 或 16）

### 2. 数据结构设计（SFS/VFS 层）

SFS inode 已有 `nlinks` 字段，可直接用于硬链接引用计数。需要扩展 inode 类型以表示软链接：

```c
// SFS inode type 扩展
#define SFS_TYPE_SYMLINK  0x0003   // 示例：新增一种类型

// 对软链接：din->size 表示 target 字符串长度（含 '\0' 可选）
// target 字符串作为“文件内容”存放在数据块中（复用普通文件的数据块索引）
```

VFS 层可为 inode_ops 增加（或复用）操作：

- `vop_link` / `vop_unlink`（硬链接）
- `vop_symlink` / `vop_readlink`（软链接）
- 路径解析（`vfs_lookup`/`vfs_lookup_parent`）在遇到 symlink 时按规则替换路径继续解析

### 3. 接口设计（语义）

系统调用建议：

- `int sys_link(const char *oldpath, const char *newpath);`
- `int sys_unlink(const char *path);`
- `int sys_symlink(const char *target, const char *linkpath);`
- `ssize_t sys_readlink(const char *linkpath, char *buf, size_t bufsz);`
- `int sys_lstat(const char *path, struct stat *st);`（可选，用于“不跟随 symlink”的 stat）

核心语义：

- `sys_link`：找到 old inode，检查类型（不允许目录等），在 newpath 目录下新增 dirent 指向 old inode；`nlinks++`
- `sys_unlink`：删除 dirent；`nlinks--`；若为 0 且无引用则回收 inode 与数据块
- `sys_symlink`：创建新 inode（SYMLINK），写入 target 字符串到数据块
- `sys_readlink`：读取该 inode 的内容（target 字符串）返回

### 4. 同步互斥与一致性

需要显式处理的关键问题：

- **目录项更新与 inode 引用计数更新的原子性**：`link/unlink` 必须保证“dirent 与 nlinks 一致”
  - 建议加锁顺序：先锁父目录 inode，再锁目标 inode（固定顺序避免死锁）
- **打开文件与 unlink 的并发**：UNIX 语义允许“unlink 后仍可通过已打开 fd 继续访问”
  - 设计上需区分 inode 的 `nlinks` 与“打开引用计数”（如 `inode_ref`/`file_ref`），只有两者都归零才真正释放
- **symlink 解析递归**：需要最大深度与循环检测（防止 `a -> b -> a`）

## 八、本实验重要知识点与 OS 原理对应

- VFS 抽象：用统一 inode/file 接口屏蔽不同文件系统差异（对应“分层抽象”思想）
- inode/dirent：目录项到 inode 的映射、inode 内保存数据块索引（对应“索引分配/索引节点”）
- 文件描述符与打开文件表：进程内 fd → file → inode（对应“进程资源表/引用计数”）
- exec 机制：建立新 mm、加载 ELF 段、构造用户栈与 trapframe（对应“程序装载/地址空间切换/特权级切换”）
- pipe/链接：分别对应 IPC（生产者消费者同步）与文件系统命名/引用模型（引用计数与路径解析）

## 九、OS 原理中重要但实验未覆盖的点（举例）

- 缓冲区缓存/页缓存（buffer cache / page cache）与写回策略（write-back）
- 崩溃一致性与日志文件系统（journaling）、事务/检查点
- 完整的权限模型（UID/GID/ACL）、挂载与命名空间
- 更复杂的 IPC（socket、匿名/命名管道、epoll/select 等）
